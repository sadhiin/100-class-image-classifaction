{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\large-class-image-classifcation\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this stage is responsible for processing the data\n",
    "# pre-requsite is the data should be downloaded... locally.\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"100-class-image-classifaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\large-class-image-classifcation\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    root_dir: Path\n",
    "    model_path: Path\n",
    "    trained_model_path: Path\n",
    "    model_name: str\n",
    "\n",
    "    dataset_path: str\n",
    "    batch_size: int\n",
    "    seed: int\n",
    "    rescale: float\n",
    "    shear_range: float\n",
    "    zoom_range: float\n",
    "    width_shift_range: float\n",
    "    height_shift_range: float\n",
    "    horizontal_flip: bool\n",
    "    validation_split: float\n",
    "    fill_mode: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LCIC.constants import *\n",
    "from LCIC import logger\n",
    "from LCIC.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_path: Path = CONFIG_FILE_PATH,\n",
    "                 params_path: Path = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        create_directories([self.config.model_training.root_dir])\n",
    "\n",
    "    def get_model_train_config(self) -> ModelTrainingConfig:\n",
    "\n",
    "        preprocessed_cfg = self.config.data_processing\n",
    "        model_cfg = self.config.model_training\n",
    "        self.params = self.params[model_cfg.model_name]\n",
    "\n",
    "        logger.info(f\"Model configurations: ---> {model_cfg}\")\n",
    "        logger.info(f\"Model parameters: ---> {preprocessed_cfg}\")\n",
    "        logger.info(\n",
    "            f\"Data Preprocessing configurations: ---> {preprocessed_cfg}\")\n",
    "\n",
    "        _cfg = ModelTrainingConfig(\n",
    "            root_dir=Path(model_cfg.root_dir),\n",
    "            model_path=Path(model_cfg.model_path),\n",
    "            trained_model_path=Path(model_cfg.trained_model_path),\n",
    "            model_name=model_cfg.model_name,\n",
    "\n",
    "            dataset_path=input(\n",
    "                \"Enter the data path: \") if preprocessed_cfg.dataset_path is None else preprocessed_cfg.dataset_path,\n",
    "            batch_size=preprocessed_cfg.batch_size,\n",
    "            seed=preprocessed_cfg.seed,\n",
    "            rescale=preprocessed_cfg.rescale,\n",
    "            shear_range=preprocessed_cfg.shear_range,\n",
    "            zoom_range=preprocessed_cfg.zoom_range,\n",
    "            width_shift_range=preprocessed_cfg.width_shift_range,\n",
    "            height_shift_range=preprocessed_cfg.height_shift_range,\n",
    "            horizontal_flip=preprocessed_cfg.horizontal_flip,\n",
    "            validation_split=preprocessed_cfg.validation_split,\n",
    "            fill_mode=preprocessed_cfg.fill_mode,\n",
    "\n",
    "        )\n",
    "        return _cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing():\n",
    "    def __init__(self,\n",
    "                 config: ModelTrainingConfig,\n",
    "                 params_path: Path = PARAMS_FILE_PATH):\n",
    "        self.config = config\n",
    "        self.params = read_yaml(params_path)\n",
    "        # setting the params for to have the target size and classes of the model\n",
    "        self.params = self.params[self.config.model_name]\n",
    "\n",
    "        self.train_generator = None\n",
    "        self.valid_generator = None\n",
    "\n",
    "    def __generator(self):\n",
    "        _train_datagen = ImageDataGenerator(\n",
    "            rescale=self.config.rescale,\n",
    "            shear_range=self.config.shear_range,\n",
    "            zoom_range=self.config.zoom_range,\n",
    "            width_shift_range=self.config.width_shift_range,\n",
    "            height_shift_range=self.config.height_shift_range,\n",
    "            horizontal_flip=self.config.horizontal_flip,\n",
    "            validation_split=self.config.validation_split,\n",
    "            fill_mode=self.config.fill_mode,\n",
    "            batch_size=self.config.batch_size\n",
    "        )\n",
    "\n",
    "        _test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        return _train_datagen, _test_datagen\n",
    "\n",
    "    def get_train_and_valid_set(self):\n",
    "        train_datagen, val_datagen = self.__generator()\n",
    "\n",
    "        training_set = train_datagen.flow_from_directory(\n",
    "            directory=self.config.dataset_path,\n",
    "            target_size=self.params.IMAGE_SIZE,\n",
    "            color_mode='rgb',\n",
    "            classes=self.params.CLASSES,\n",
    "            class_mode='categorical',\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=True,\n",
    "            seed=self.config.seed,\n",
    "            interpolation='nearest',\n",
    "            subset=\"training\"\n",
    "        )\n",
    "\n",
    "        validation_set = val_datagen.flow_from_directory(\n",
    "            directory=self.config.dataset_path,\n",
    "            target_size=self.params.IMAGE_SIZE,\n",
    "            color_mode='rgb',\n",
    "            classes=self.params.CLASSES,\n",
    "            class_mode='categorical',\n",
    "            batch_size=self.config.batch_size,\n",
    "            interpolation='nearest',\n",
    "            subset=\"validation\"\n",
    "        )\n",
    "\n",
    "        self.train_generator =  training_set\n",
    "        self.valid_generator = validation_set\n",
    "\n",
    "        return self.train_generator, self.valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training():\n",
    "    def __init__(self, config: ModelTrainingConfig,\n",
    "                 params_path: Path = PARAMS_FILE_PATH) -> None:\n",
    "        self.config = config\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        self.training_data, self.validation_data = DataPreprocessing(\n",
    "            config=self.config).get_train_and_valid_set()\n",
    "\n",
    "        self.trains_steps = self.training_data.samples // self.config.batch_size\n",
    "        self.validation_steps = self.validation_data.samples // self.config.batch_size\n",
    "        self.model = tf.keras.load_model(self.config.model_path)\n",
    "        self.history = None\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(model: tf.keras.Model, path: Path):\n",
    "        model.save(path)\n",
    "\n",
    "    def __getoptimizer(self, optimizer_name: str):\n",
    "        if optimizer_name == \"adam\":\n",
    "            return tf.keras.optimizers.Adam(learning_rate=self.params.LEARNING_RATE, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "        elif optimizer_name == \"rmsprop\":\n",
    "            return tf.keras.optimizers.RMSprop(learning_rate=self.params.LEARNING_RATE, rho=0.9)\n",
    "        elif optimizer_name == \"sgd\":\n",
    "            return tf.keras.optimizers.SGD(learning_rate=self.params.LEARNING_RATE, momentum=0.0, nesterov=False)\n",
    "\n",
    "    def train(self, callbacks_list: list = [], save_model: bool = True, gethistory: bool = True):\n",
    "\n",
    "        self.model.compile(optimizer=self.__getoptimizer(self.params.OPTIMIZER),\n",
    "                           loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "        self.history = self.model.fit(self.training_data,\n",
    "                                      steps_per_epoch=self.trains_steps,\n",
    "                                      epochs=self.params.EPOCHS,\n",
    "                                      validation_data=self.validation_data,\n",
    "                                      validation_steps=self.validation_steps,\n",
    "                                      callbacks=callbacks_list)\n",
    "        if save_model:\n",
    "            self.save_model(self.model, self.config.trained_model_path)\n",
    "        if gethistory:\n",
    "            return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     config_mgr = ConfigurationManager()\n",
    "#     preprocess_config = config_mgr.get_preprocess_config()\n",
    "#     data_preprocessing = DataPreprocessing(preprocess_config)\n",
    "#     training_set, validation_set = data_preprocessing.get_train_and_valid_set()\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_mgr = ConfigurationManager()\n",
    "    preprocess_config = config_mgr.get_model_train_config()\n",
    "    training = Training(preprocess_config)\n",
    "    training.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
